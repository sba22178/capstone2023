{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a19774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59cdb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "803a8153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Greyhound Name</th>\n",
       "      <th>Earmark</th>\n",
       "      <th>Microchip</th>\n",
       "      <th>Reg Date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Whelp Date</th>\n",
       "      <th>Retirement Type</th>\n",
       "      <th>OccuredAt</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COOLEMORE COUNT</td>\n",
       "      <td>YVRYL</td>\n",
       "      <td>9.772000e+14</td>\n",
       "      <td>12/02/2022</td>\n",
       "      <td>B</td>\n",
       "      <td>12/02/2022</td>\n",
       "      <td>EUT</td>\n",
       "      <td>07/12/2023 14:41</td>\n",
       "      <td>EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPOOK MAGOO</td>\n",
       "      <td>UNBET</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>10/10/2018</td>\n",
       "      <td>D</td>\n",
       "      <td>21/04/2019</td>\n",
       "      <td>EUT</td>\n",
       "      <td>07/12/2023 12:24</td>\n",
       "      <td>EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PECKIES DAFFY</td>\n",
       "      <td>VYRAJ</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>07/05/2021</td>\n",
       "      <td>B</td>\n",
       "      <td>26/03/2020</td>\n",
       "      <td>EUT</td>\n",
       "      <td>07/12/2023 11:34</td>\n",
       "      <td>EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPOOK MAGOO</td>\n",
       "      <td>UNBET</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>10/10/2018</td>\n",
       "      <td>D</td>\n",
       "      <td>21/04/2019</td>\n",
       "      <td>RET</td>\n",
       "      <td>07/12/2023 11:24</td>\n",
       "      <td>RAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHELONE KING</td>\n",
       "      <td>UUKTL</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>15/04/2019</td>\n",
       "      <td>D</td>\n",
       "      <td>15/04/2019</td>\n",
       "      <td>EUT</td>\n",
       "      <td>07/12/2023 10:25</td>\n",
       "      <td>EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233750</th>\n",
       "      <td>KNOCKGLASS KING</td>\n",
       "      <td>VPISU</td>\n",
       "      <td>9.772000e+14</td>\n",
       "      <td>01/04/2021</td>\n",
       "      <td>D</td>\n",
       "      <td>18/03/2020</td>\n",
       "      <td>EUT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233751</th>\n",
       "      <td>HELLO HOLLIE</td>\n",
       "      <td>TDVXR</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>23/04/2021</td>\n",
       "      <td>B</td>\n",
       "      <td>04/08/2018</td>\n",
       "      <td>EUT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233752</th>\n",
       "      <td>SEOMRA DISC</td>\n",
       "      <td>UYIKE</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>04/05/2021</td>\n",
       "      <td>D</td>\n",
       "      <td>12/12/2019</td>\n",
       "      <td>EUT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233753</th>\n",
       "      <td>KILWEST NOAH</td>\n",
       "      <td>VVTMH</td>\n",
       "      <td>9.772000e+14</td>\n",
       "      <td>24/11/2021</td>\n",
       "      <td>D</td>\n",
       "      <td>20/09/2020</td>\n",
       "      <td>EUT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233754</th>\n",
       "      <td>CHEEKY CHAR</td>\n",
       "      <td>ZYH2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/01/2022</td>\n",
       "      <td>D</td>\n",
       "      <td>18/08/2020</td>\n",
       "      <td>EUT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233755 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Greyhound Name Earmark     Microchip    Reg Date Sex  Whelp Date  \\\n",
       "0       COOLEMORE COUNT   YVRYL  9.772000e+14  12/02/2022   B  12/02/2022   \n",
       "1           SPOOK MAGOO   UNBET  9.722740e+14  10/10/2018   D  21/04/2019   \n",
       "2         PECKIES DAFFY   VYRAJ  9.722740e+14  07/05/2021   B  26/03/2020   \n",
       "3           SPOOK MAGOO   UNBET  9.722740e+14  10/10/2018   D  21/04/2019   \n",
       "4          SHELONE KING   UUKTL  9.722740e+14  15/04/2019   D  15/04/2019   \n",
       "...                 ...     ...           ...         ...  ..         ...   \n",
       "233750  KNOCKGLASS KING   VPISU  9.772000e+14  01/04/2021   D  18/03/2020   \n",
       "233751     HELLO HOLLIE   TDVXR  9.722740e+14  23/04/2021   B  04/08/2018   \n",
       "233752      SEOMRA DISC   UYIKE  9.722740e+14  04/05/2021   D  12/12/2019   \n",
       "233753     KILWEST NOAH   VVTMH  9.772000e+14  24/11/2021   D  20/09/2020   \n",
       "233754      CHEEKY CHAR    ZYH2           NaN  18/01/2022   D  18/08/2020   \n",
       "\n",
       "       Retirement Type         OccuredAt Status  \n",
       "0                  EUT  07/12/2023 14:41    EUT  \n",
       "1                  EUT  07/12/2023 12:24    EUT  \n",
       "2                  EUT  07/12/2023 11:34    EUT  \n",
       "3                  RET  07/12/2023 11:24    RAC  \n",
       "4                  EUT  07/12/2023 10:25    EUT  \n",
       "...                ...               ...    ...  \n",
       "233750             EUT               NaN    EUT  \n",
       "233751             EUT               NaN    EUT  \n",
       "233752             EUT               NaN    EUT  \n",
       "233753             EUT               NaN    EUT  \n",
       "233754             EUT               NaN    EUT  \n",
       "\n",
       "[233755 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa826f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1793c7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danma\\AppData\\Local\\Temp\\ipykernel_15280\\371761573.py:2: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df[\"Whelp Date\"] = pd.to_datetime(df[\"Whelp Date\"])\n",
      "C:\\Users\\danma\\AppData\\Local\\Temp\\ipykernel_15280\\371761573.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Whelp Date\"] = pd.to_datetime(df[\"Whelp Date\"])\n",
      "C:\\Users\\danma\\AppData\\Local\\Temp\\ipykernel_15280\\371761573.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"OccuredAt\"] = pd.to_datetime(df[\"OccuredAt\"])\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime format\n",
    "df[\"Whelp Date\"] = pd.to_datetime(df[\"Whelp Date\"])\n",
    "df[\"OccuredAt\"] = pd.to_datetime(df[\"OccuredAt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d3d0102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danma\\AppData\\Local\\Temp\\ipykernel_15280\\632837499.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Career Length\"] = (df[\"OccuredAt\"] - df[\"Whelp Date\"]).dt.days\n"
     ]
    }
   ],
   "source": [
    "# Calculate Career Length and classify into categories\n",
    "df[\"Career Length\"] = (df[\"OccuredAt\"] - df[\"Whelp Date\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b8e0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Greyhound Name</th>\n",
       "      <th>Earmark</th>\n",
       "      <th>Microchip</th>\n",
       "      <th>Reg Date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Whelp Date</th>\n",
       "      <th>Retirement Type</th>\n",
       "      <th>OccuredAt</th>\n",
       "      <th>Status</th>\n",
       "      <th>Career Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COOLEMORE COUNT</td>\n",
       "      <td>YVRYL</td>\n",
       "      <td>9.772000e+14</td>\n",
       "      <td>12/02/2022</td>\n",
       "      <td>B</td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>EUT</td>\n",
       "      <td>2023-07-12 14:41:00</td>\n",
       "      <td>EUT</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPOOK MAGOO</td>\n",
       "      <td>UNBET</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>10/10/2018</td>\n",
       "      <td>D</td>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>EUT</td>\n",
       "      <td>2023-07-12 12:24:00</td>\n",
       "      <td>EUT</td>\n",
       "      <td>1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PECKIES DAFFY</td>\n",
       "      <td>VYRAJ</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>07/05/2021</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>EUT</td>\n",
       "      <td>2023-07-12 11:34:00</td>\n",
       "      <td>EUT</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPOOK MAGOO</td>\n",
       "      <td>UNBET</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>10/10/2018</td>\n",
       "      <td>D</td>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>RET</td>\n",
       "      <td>2023-07-12 11:24:00</td>\n",
       "      <td>RAC</td>\n",
       "      <td>1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHELONE KING</td>\n",
       "      <td>UUKTL</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>15/04/2019</td>\n",
       "      <td>D</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>EUT</td>\n",
       "      <td>2023-07-12 10:25:00</td>\n",
       "      <td>EUT</td>\n",
       "      <td>1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229956</th>\n",
       "      <td>KIWI SANDY</td>\n",
       "      <td>UTRBS</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>12/09/2019</td>\n",
       "      <td>B</td>\n",
       "      <td>2019-10-26</td>\n",
       "      <td>EUT</td>\n",
       "      <td>2021-10-01 06:01:00</td>\n",
       "      <td>EUT</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229957</th>\n",
       "      <td>COUGARS HERO</td>\n",
       "      <td>USQIE</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>18/02/2020</td>\n",
       "      <td>D</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>EUT</td>\n",
       "      <td>2021-10-01 06:01:00</td>\n",
       "      <td>EUT</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229958</th>\n",
       "      <td>CLASSIC SYLVIA</td>\n",
       "      <td>UBDZZ</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>15/04/2021</td>\n",
       "      <td>B</td>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>DIE</td>\n",
       "      <td>2021-10-01 06:01:00</td>\n",
       "      <td>REG</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229959</th>\n",
       "      <td>VIEW HERMOINE</td>\n",
       "      <td>UPVXM</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>04/10/2019</td>\n",
       "      <td>B</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>EUT</td>\n",
       "      <td>2021-10-01 06:01:00</td>\n",
       "      <td>EUT</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229960</th>\n",
       "      <td>DARBYS STORM</td>\n",
       "      <td>THSYE</td>\n",
       "      <td>9.722740e+14</td>\n",
       "      <td>17/10/2018</td>\n",
       "      <td>D</td>\n",
       "      <td>2018-07-14</td>\n",
       "      <td>EUT</td>\n",
       "      <td>2021-10-01 06:01:00</td>\n",
       "      <td>EUT</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224190 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Greyhound Name Earmark     Microchip    Reg Date Sex Whelp Date  \\\n",
       "0       COOLEMORE COUNT   YVRYL  9.772000e+14  12/02/2022   B 2022-12-02   \n",
       "1           SPOOK MAGOO   UNBET  9.722740e+14  10/10/2018   D 2019-04-21   \n",
       "2         PECKIES DAFFY   VYRAJ  9.722740e+14  07/05/2021   B 2020-03-26   \n",
       "3           SPOOK MAGOO   UNBET  9.722740e+14  10/10/2018   D 2019-04-21   \n",
       "4          SHELONE KING   UUKTL  9.722740e+14  15/04/2019   D 2019-04-15   \n",
       "...                 ...     ...           ...         ...  ..        ...   \n",
       "229956       KIWI SANDY   UTRBS  9.722740e+14  12/09/2019   B 2019-10-26   \n",
       "229957     COUGARS HERO   USQIE  9.722740e+14  18/02/2020   D 2019-01-10   \n",
       "229958   CLASSIC SYLVIA   UBDZZ  9.722740e+14  15/04/2021   B 2019-03-10   \n",
       "229959    VIEW HERMOINE   UPVXM  9.722740e+14  04/10/2019   B 2019-12-06   \n",
       "229960     DARBYS STORM   THSYE  9.722740e+14  17/10/2018   D 2018-07-14   \n",
       "\n",
       "       Retirement Type           OccuredAt Status  Career Length  \n",
       "0                  EUT 2023-07-12 14:41:00    EUT            222  \n",
       "1                  EUT 2023-07-12 12:24:00    EUT           1543  \n",
       "2                  EUT 2023-07-12 11:34:00    EUT           1203  \n",
       "3                  RET 2023-07-12 11:24:00    RAC           1543  \n",
       "4                  EUT 2023-07-12 10:25:00    EUT           1549  \n",
       "...                ...                 ...    ...            ...  \n",
       "229956             EUT 2021-10-01 06:01:00    EUT            706  \n",
       "229957             EUT 2021-10-01 06:01:00    EUT            995  \n",
       "229958             DIE 2021-10-01 06:01:00    REG            936  \n",
       "229959             EUT 2021-10-01 06:01:00    EUT            665  \n",
       "229960             EUT 2021-10-01 06:01:00    EUT           1175  \n",
       "\n",
       "[224190 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbdef0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a00cbadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# let's say you want to predict \"Career Length\"\n",
    "X = df.drop([\"Career Length\", \"OccuredAt\"], axis=1)\n",
    "y = df[\"Career Length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ffe4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19700e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 26/42 [08:47<20:34, 77.18s/it]"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the LazyRegressor\n",
    "reg = LazyRegressor(verbose=0)\n",
    "models,predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Display the model performance\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b7495",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2affd5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aabe378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebda2b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example data (replace with your actual data)\n",
    "X_train = np.random.rand(100, 10)  # 100 samples, 10 features\n",
    "y_train = np.random.randint(2, size=100)  # Binary classification labels (0 or 1)\n",
    "\n",
    "# Convert data types if necessary\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa42bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd734e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "688d619b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load your dataset here (replace this with your data loading code)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Preprocess your data (convert date columns, handle missing values, one-hot encode categorical variables)\n",
    "# ...\n",
    "\n",
    "# Create features and target variables\n",
    "X = df.drop([\"Status\"], axis=1)  # Features\n",
    "y = df[\"Status\"]  # Target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c05002ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cc15158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/4 [======>.......................] - ETA: 3s - loss: 0.6965 - accuracy: 0.5000"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Change loss for multi-class classification\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # Change loss for multi-class classification\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c16b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
